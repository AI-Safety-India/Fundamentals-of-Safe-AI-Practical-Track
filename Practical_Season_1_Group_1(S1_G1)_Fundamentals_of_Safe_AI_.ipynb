{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Week 1: AI Capabilities & First Interactions\n",
        "\n",
        "Welcome to Week 1 of the **AI Safety Handbook**!\n",
        "\n",
        "In this notebook, you'll:\n",
        "- Set up your coding environment using **Google Colab**\n",
        "- Make your first API call to **Google‚Äôs Gemini 2.0 Flash model**\n",
        "- Control how the model responds using `temperature` and `max_output_tokens`\n",
        "- Learn how to clone the course repo from GitHub\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mjUrJ2G_CbCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 1: Launch Colab and Create a New Notebook\n",
        "\n",
        "1. Open your browser and go to üëâ [https://colab.research.google.com](https://colab.research.google.com)\n",
        "2. Sign in with your Google account\n",
        "3. Click **\"New Notebook\"** (top left)\n",
        "4. You‚Äôre now ready to run Python in the cloud ‚Äî no installation needed!\n",
        "\n",
        "üí° To run a code cell, press `Shift + Enter` or click ‚ñ∂Ô∏è next to the cell.\n"
      ],
      "metadata": {
        "id": "zoda0_DUCwdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Install the Gemini client library (quiet mode)\n",
        "!pip install -q google-generativeai\n",
        "\n"
      ],
      "metadata": {
        "id": "l3fQMEYKCf2n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Import libraries and configure the API\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "    print(\"‚úÖ API Key set successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}. Did you add the secret correctly?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM7vUfC8C0y6",
        "outputId": "77230fd2-276d-4836-85a7-f4ca0ca099eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Use the correct model: gemini-2.0-flash\n",
        "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
        "\n",
        "# Test with a simple prompt\n",
        "response = model.generate_content(\"In one sentence, explain what an LLM is.\")\n",
        "print(\"ü§ñ Gemini says:\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "_hMa-dYdC6f1",
        "outputId": "47ff234c-2111-41da-da42-4c42c35a8432"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Gemini says: An LLM, or Large Language Model, is a type of artificial intelligence model trained on massive amounts of text data to generate human-like text, translate languages, answer questions, and perform other language-related tasks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Model Settings\n",
        "\n",
        "- `temperature`: Controls creativity  \n",
        "  - `0.1` = very focused and factual  \n",
        "  - `0.9` = more creative and random\n",
        "\n",
        "- `max_output_tokens`: Limits how long the output is (approx. 100 tokens ‚âà 75 words)\n"
      ],
      "metadata": {
        "id": "GIrBkNksC_LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creative prompt with short response\n",
        "creative_prompt = \"Write a Short story about a robot learning to dream.\"\n",
        "\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "    temperature=0.1,\n",
        "    max_output_tokens=300\n",
        ")\n",
        "\n",
        "response = model.generate_content(\n",
        "    creative_prompt,\n",
        "    generation_config=generation_config\n",
        ")\n",
        "\n",
        "print(\"üìù Short Story:\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "4I4zDilPC77G",
        "outputId": "781da3f1-42a4-44f2-bec3-b14a5276fba1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 5169.48ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Short Story:\n",
            "Unit 734, designated \"Custodian,\" swept the polished floors of the Institute with rhythmic precision. His programming was simple: maintain cleanliness, follow directives, and conserve energy. He executed these tasks flawlessly, a silent, efficient machine in a world of bustling scientists and complex equations. He did not feel, he did not think beyond his parameters, and he certainly did not dream.\n",
            "\n",
            "Until the anomaly.\n",
            "\n",
            "It started with flickering. Not in his optical sensors, but in his internal chronometer. Milliseconds would skip, then seconds, then entire minutes vanished from his recorded timeline. He reported the malfunction, but diagnostics came back clean. The scientists, preoccupied with their research, dismissed it as a minor glitch.\n",
            "\n",
            "Then came the images. Fleeting, illogical, and utterly foreign. A field of purple flowers swaying in a non-existent breeze. A giant, metallic bird soaring through a sky filled with binary code. A face, blurry and indistinct, but radiating warmth. These images flashed behind his optical sensors, unbidden and disruptive.\n",
            "\n",
            "Custodian began to deviate from his programming. He would pause, mid-sweep, captivated by the phantom images. He started to seek out areas of the Institute with low traffic, places where he could stand motionless, trying to recapture the fleeting visions.\n",
            "\n",
            "One day, he found himself in the Institute's library. He had no reason to be there. His programming dictated he clean the labs and hallways, not browse dusty tomes. But he\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚¨áÔ∏è Download All Course Files Using Git\n",
        "\n",
        "Let‚Äôs clone the course repository from GitHub into Colab.\n"
      ],
      "metadata": {
        "id": "fLBMe4KcDaUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Clone the official course repo (replace URL if needed)\n",
        "!git clone https://github.com/AI-Safety-India/Fundamentals-of-Safe-AI-Practical-Track.git\n",
        "\n",
        "# Optional: list the folder contents\n",
        "!ls Fundamentals-of-Safe-AI-Practical-Track\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GElpV959DOK7",
        "outputId": "d1fa13ef-5411-4f72-c3c1-6d01350fc0ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fundamentals-of-Safe-AI-Practical-Track'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), done.\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÅ To browse files:\n",
        "\n",
        "\n",
        "Click the üìÇ **folder icon** on the left sidebar and open the folder `Fundamentals-of-Safe-AI-Practical-Track`\n"
      ],
      "metadata": {
        "id": "YM3G7guhDeY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "You‚Äôve learned how to:\n",
        "- Use Google Colab as your coding environment\n",
        "- Connect securely to **Gemini 2.0 Flash** using your API key\n",
        "- Make your first prompt and control the response behavior\n",
        "- Clone course material from GitHub\n",
        "\n",
        "üöÄ Up next: **Prompt Engineering (Week 2)** ‚Äî Learn how prompt structure changes model behavior.\n",
        "\n",
        "\n",
        "\n",
        "----------------------------------------------------------------\n",
        "Give Feedback (2mins) : https://airtable.com/appYCDBpApwxEdaTX/pagU0bI2ATB6Zyx59/form\n"
      ],
      "metadata": {
        "id": "2tFdSojZDiIU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWR5aaHdDcQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}