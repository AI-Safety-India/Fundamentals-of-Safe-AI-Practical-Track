# 🧠 Fundamentals of Safe AI — AI Safety India

Welcome to the **AI Safety Technical Handbook**, a hands-on, week-by-week coding curriculum designed to help you **build, test, and understand safe AI systems** — from first prompts to interpretability.

🌐 Visit us at [**aisafetyindia.com**](https://aisafetyindia.com)

---

## 📘 About This Handbook

This repository is your step-by-step guide for learning **technical AI safety**. It’s built for students, researchers, and curious builders who want to deeply understand **how to interact with, evaluate, and improve language models**.

Each week introduces a key concept in AI safety, along with hands-on coding labs using Google's **Gemini API**.

---

## 🔍 Weekly Topics

- **Week 1:** First Interactions – How language models behave by default  
- **Week 2:** Prompt Engineering – Controlling model behavior with input design  
- **Week 3:** Red Teaming – Discovering model failures and loopholes  
- **Week 4:** AI Governance – Who manages AI and how policy shapes safety  
- **Week 5:** AI Evaluations – Measuring model safety and alignment  
- **Week 6:** Reward Hacking – What goes wrong when objectives aren’t aligned  
- **Week 7:** Model Consistency – Do models reason consistently across prompts?  
- **Week 8:** Scalable Oversight – Can humans safely oversee more capable AIs?  
- **Week 9:** Interpretability – Understanding what’s going on inside the model

---

## 🚀 Getting Started

> No advanced background required. Just **basic Python** and a desire to explore AI critically.

Each week includes:
- A focused learning module  
- Practical exercises using the [**Free Gemini API Key**](https://aistudio.google.com/apikey)  
- Clean, reproducible code (Colab & local)  
- Real-world case studies focused on safety  

---

## 🧪 Tools You'll Use

- 🧠 **Gemini Pro API** (free access via Google)
- 🐍 Python 3.9+
- 📓 Google Colab (recommended)
- 💻 Any IDE like VS Code

---

## 🌍 Why This Matters

AI is shaping our world fast. But power without safety is risk.

By learning to **identify, test, and fix** AI misbehaviors, you're joining a global movement to build AI that’s **reliable, aligned, and beneficial** for all.

This handbook is our small step toward making **AI safety accessible** in India and beyond.

---

## 👥 Created By

**AI Safety India** – a growing community of students, builders, and researchers working to make AI development more responsible, transparent, and safe.

🔗 Learn more at [**aisafetyindia.com**](https://aisafetyindia.com)

---

## 🤝 Contribute

We welcome:
- Improvements to code or content
- New exercises or ideas
- Translations or localization help

📩 Open an issue or send a pull request to get involved.

---

### 🚧 Let’s build safer AI systems.
