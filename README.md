# ğŸ§  Fundamentals of Safe AI â€” AI Safety India

Welcome to the **AI Safety Technical Handbook**, a hands-on, week-by-week coding curriculum designed to help you **build, test, and understand safe AI systems** â€” from first prompts to interpretability.

ğŸŒ Visit us at [**aisafetyindia.com**](https://aisafetyindia.com)

---

## ğŸ“˜ About This Handbook

This repository is your step-by-step guide for learning **technical AI safety**. Itâ€™s built for students, researchers, and curious builders who want to deeply understand **how to interact with, evaluate, and improve language models**.

Each week introduces a key concept in AI safety, along with hands-on coding labs using Google's **Gemini API**.

---

## ğŸ” Weekly Topics

- **Week 1:** First Interactions â€“ How language models behave by default  
- **Week 2:** Prompt Engineering â€“ Controlling model behavior with input design  
- **Week 3:** Red Teaming â€“ Discovering model failures and loopholes  
- **Week 4:** AI Governance â€“ Who manages AI and how policy shapes safety  
- **Week 5:** AI Evaluations â€“ Measuring model safety and alignment  
- **Week 6:** Reward Hacking â€“ What goes wrong when objectives arenâ€™t aligned  
- **Week 7:** Model Consistency â€“ Do models reason consistently across prompts?  
- **Week 8:** Scalable Oversight â€“ Can humans safely oversee more capable AIs?  
- **Week 9:** Interpretability â€“ Understanding whatâ€™s going on inside the model

---

## ğŸš€ Getting Started

> No advanced background required. Just **basic Python** and a desire to explore AI critically.

Each week includes:
- A focused learning module  
- Practical exercises using the [**Free Gemini API Key**](https://aistudio.google.com/apikey)  
- Clean, reproducible code (Colab & local)  
- Real-world case studies focused on safety  

---

## ğŸ§ª Tools You'll Use

- ğŸ§  **Gemini Pro API** (free access via Google)
- ğŸ Python 3.9+
- ğŸ““ Google Colab (recommended)
- ğŸ’» Any IDE like VS Code

---

## ğŸŒ Why This Matters

AI is shaping our world fast. But power without safety is risk.

By learning to **identify, test, and fix** AI misbehaviors, you're joining a global movement to build AI thatâ€™s **reliable, aligned, and beneficial** for all.

This handbook is our small step toward making **AI safety accessible** in India and beyond.

---

## ğŸ‘¥ Created By

**AI Safety India** â€“ a growing community of students, builders, and researchers working to make AI development more responsible, transparent, and safe.

ğŸ”— Learn more at [**aisafetyindia.com**](https://aisafetyindia.com)

---

## ğŸ¤ Contribute

We welcome:
- Improvements to code or content
- New exercises or ideas
- Translations or localization help

ğŸ“© Open an issue or send a pull request to get involved.

---

### ğŸš§ Letâ€™s build safer AI systems.
